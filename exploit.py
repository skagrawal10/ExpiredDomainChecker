from StringIO import StringIO
import gzip
import urllib2
import lxml 
import lxml.html
import csv
from postGreyImpl import *


connectToDatabase();
exploit_output_file = csv.writer(open('exploit_output_file.csv','wb'))
exploit_output_file.writerow(['Url','EDB_ID','CVE','OSVDB_ID','Verified','Author','Published','Download Exploit','Download Vulnerable','Type'])

url_dict = {'https://www.exploit-db.com/remote/?order_by=date&order=desc&pg=[pg_no]':['remote',313],'https://www.exploit-db.com/webapps/?order_by=date&order=desc&pg=[pg_no]':['webapps',1021],'https://www.exploit-db.com/local/?order_by=date&order=desc&pg=[pg_no]':['local',158],'https://www.exploit-db.com/dos/?order_by=date&order=desc&pg=[pg_no]':['dos',239],'https://www.exploit-db.com/shellcode/?order_by=date&order=desc&pg=[pg_no]':['shellcode',27]}
#,'https://www.exploit-db.com/papers/?order_by=date&order=desc&pg=[pg_no]':['papers',58],}

base_url = 'https://www.exploit-db.com/papers/?order_by=date&order=desc&pg=[pg_no]'

for i in range(1,58):
	try:
		ss = str(i)
		request = urllib2.Request(base_url.replace('[pg_no]',ss))
		print base_url.replace('[pg_no]',ss);
		request.add_header('Accept-encoding', 'gzip')
		response = urllib2.urlopen(request)
		if response.info().get('Content-Encoding') == 'gzip':
			buf = StringIO(response.read());
			f = gzip.GzipFile(fileobj=buf)
			data = f.read()
			doc1 = lxml.html.document_fromstring(data)
			list_row = doc1.xpath('//td[@class="description"]/a/@href')
			list_text = doc1.xpath('//td[@class="description"]/a/text()')
			c = 1
			for text in list_text:
				try:
					exploit_output_file.writerow([list_row[c],text.encode('utf-8'),'','','','','','','','papers'])
					insertExploitInDb(text.encode('utf-8'),'','','0','','', 'papers');
					c+=1
					
				except:
					c+=1
					#raise;
					print 'error';
		# break
	except Exception as e:
		print(e);
		#raise;
#exit();

for key,value in url_dict.items():
	try:
		_type = value[0]
		_range = value[1]
		_url = key

		for i in range(1,_range):
			ss = str(i)
			request = urllib2.Request(_url.replace('[pg_no]',ss))
			print _url.replace('[pg_no]',ss);
			request.add_header('Accept-encoding', 'gzip')
			response = urllib2.urlopen(request)
			if response.info().get('Content-Encoding') == 'gzip':
				buf = StringIO( response.read())
				f = gzip.GzipFile(fileobj=buf)
				data = f.read()
				doc1 = lxml.html.document_fromstring(data)
				list_row = doc1.xpath('//td[@class="description"]/a/@href')



				for row in list_row:
					try:
						request = urllib2.Request(row)
						request.add_header('Accept-encoding', 'gzip')
						response = urllib2.urlopen(request)
						if response.info().get('Content-Encoding') == 'gzip':
							buf = StringIO( response.read())
							f = gzip.GzipFile(fileobj=buf)
							data = f.read()
							doc1 = lxml.html.document_fromstring(data)

							edb_id = doc1.xpath('//table[@class="exploit_list"]//tr[1]/td[1]/text()')
							if len(edb_id)>0:
								edb_id = edb_id[0].strip()

							cve = doc1.xpath('//table[@class="exploit_list"]//tr[1]/td[2]/a/text()')
							if len(cve)>0:
								cve = cve[0].strip()
							else:
								cve = doc1.xpath('//table[@class="exploit_list"]//tr[1]/td[2]/text()')
								if len(cve)>0:
									cve = cve[0].strip()

							osvdb = doc1.xpath('//table[@class="exploit_list"]//tr[1]/td[3]/a/text()')
							# print osvdb
							if len(osvdb)>0:
								osvdb = osvdb[0].strip()
							else:
								osvdb = doc1.xpath('//table[@class="exploit_list"]//tr[1]/td[3]/text()')
								if len(osvdb)>0:
									osvdb = osvdb[0].strip()

							verified = doc1.xpath('//i[@class="fa fa-check-circle-o"]')
							if len(verified)>0:
								verified = '1'
							else:
								verified = '0'

							author = doc1.xpath('//table[@class="exploit_list"]//tr[2]/td[2]/a/text()')
							if len(author)>0:
								author = author[0].strip()

							published = doc1.xpath('//table[@class="exploit_list"]//tr[2]/td[3]/text()')
							if len(published)>0:
								published = published[0].strip()

							download_exploit = doc1.xpath('//table[@class="exploit_list"]//tr[3]/td[1]/a//text()')
							if len(download_exploit)>0:
								download_exploit = ','.join([ x.strip() for x in download_exploit])
								download_exploit = download_exploit.strip()

							download_vulnerable = doc1.xpath('//table[@class="exploit_list"]//tr[3]/td[2]/a/@href')
							# print download_vulnerable
							if len(download_vulnerable)>0:
								download_vulnerable = download_vulnerable[0].strip()
							else:
								download_vulnerable = doc1.xpath('//table[@class="exploit_list"]//tr[3]/td[2]/text()')
								if len(download_vulnerable)>0:
									download_vulnerable = ''.join([ x.strip() for x in download_vulnerable])
									download_vulnerable = download_vulnerable.strip()
									


							insertExploitInDb(edb_id,cve,osvdb,verified,author,published, _type);
							#exploit_output_file.writerow([row,edb_id,cve,osvdb,verified,author,published,download_exploit,download_vulnerable,_type])
							#exit();
					except:
						print(row)

		# break
	except:
		pass		